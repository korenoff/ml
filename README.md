Файл markup.json был подредактирован вручную (через replace all, чтобы у всех изображений ключ атрибутов был записан одинаково), так как тег "shape_attributes" у некоторых изображений имел другую запись: "shape-attributes". 

В папку с изображениями, которые надо обработать, закинуть файл skript.py и запустить. В консоли отобразится кол-во изображений, и кол-во корректно обработанных изображений. Обработка изображений происходит с использованием файла markup.json, где содержаться метаданные фото и координаты области, которую нужно вырезать.

В папке с изображениями скрипт создаст папку с названием "meyy", в которой будут папки с названием обработанных изображений (например в папке "stop-1" будут содержаться только изображения "stop" и т.д.)

Так же будет создан файл data.json, где будут обработанные теги изоражений с метками, к какому знаку они относятся, например: "im1.png": {"sign": "traffic-light-1"}.

После загрузки немногоподредактированных файлов на Google Drive, фото обучают (предварительно преобразованные в тензоры) нейронную сеть (ml_unfinished.ipynb - сама нейронка).

Аккуратнось при определенных эпохах достигала 80%. Скорее всего такой маленький процент предикта связан с тем, что мало данных для обучения нейронной сети, плохо оптимизированных весов (скорее всего), на это все указывает периодически возрастающий loss в эпохах. 

Нуждается в доработке. 


